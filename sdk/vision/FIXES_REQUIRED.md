# @agl/vision ç”Ÿäº§ç¯å¢ƒä¿®å¤æ¸…å•

**åŸºäºå®¡è®¡æŠ¥å‘Šçš„å…³é”®ä¿®å¤é¡¹**

---

## ğŸ”´ Phase 1: ç´§æ€¥ä¿®å¤ï¼ˆç”Ÿäº§é˜»å¡ï¼‰

### ä¿®å¤ #1: ç±»å‹å®šä¹‰ä¸å®ç°ä¸åŒ¹é…

**æ–‡ä»¶**: `src/types/index.ts`, `README.md`

**é—®é¢˜**:
```typescript
// å½“å‰å®šä¹‰
export type CaptureSource = 'canvas' | 'video' | 'display' | 'window' | 'custom';
// 'custom' æœªå®ç°ï¼Œä¼šå¯¼è‡´è¿è¡Œæ—¶é”™è¯¯
```

**ä¿®å¤æ–¹æ¡ˆ**:
```typescript
// é€‰é¡¹ A: ç§»é™¤æœªå®ç°çš„ç±»å‹ï¼ˆæ¨èï¼‰
export type CaptureSource = 'canvas' | 'video' | 'display' | 'window';

// é€‰é¡¹ B: å¦‚æœæœªæ¥éœ€è¦è‡ªå®šä¹‰æº
export interface CaptureConfig {
  source: CaptureSource;
  target?: HTMLCanvasElement | HTMLVideoElement | string;
  /**
   * Custom capture function (only used when source is 'custom')
   * @experimental
   */
  customCaptureFn?: () => Promise<Screenshot>;
}
```

**æµ‹è¯•**:
```typescript
// æ·»åŠ æµ‹è¯•
it('should throw error for unsupported capture source', async () => {
  const config: any = { source: 'unsupported' };
  const capture = new ScreenCapture(config);
  await expect(capture.capture()).rejects.toThrow('Unsupported capture source');
});
```

---

### ä¿®å¤ #2: æ·»åŠ è¾“å…¥éªŒè¯

**æ–‡ä»¶**: `src/analysis/VisionAnalyzer.ts`, `src/capture/ScreenCapture.ts`

**VisionAnalyzer éªŒè¯**:
```typescript
private normalizeConfig(config: VisionConfig): VisionConfig {
  // éªŒè¯ apiKey
  if (!config.apiKey || config.apiKey.trim() === '') {
    throw new Error('VisionConfig.apiKey is required and cannot be empty');
  }

  // éªŒè¯ temperature
  const temperature = config.temperature !== undefined ? config.temperature : 0.7;
  if (temperature < 0 || temperature > 1) {
    throw new Error('VisionConfig.temperature must be between 0 and 1, got ' + temperature);
  }

  // éªŒè¯ maxTokens
  const maxTokens = config.maxTokens || 1000;
  if (maxTokens < 1 || maxTokens > 100000) {
    throw new Error('VisionConfig.maxTokens must be between 1 and 100000, got ' + maxTokens);
  }

  return {
    provider: config.provider,
    apiKey: config.apiKey,
    model: config.model || this.getDefaultModel(config.provider),
    maxTokens,
    temperature,
    apiEndpoint: config.apiEndpoint || this.getDefaultEndpoint(config.provider),
  };
}
```

**ScreenCapture éªŒè¯**:
```typescript
private normalizeConfig(config: CaptureConfig): CaptureConfig & {
  format: ImageFormat;
  quality: number;
  maxWidth: number;
  maxHeight: number;
  interval: number;
  autoCapture: boolean;
} {
  // éªŒè¯ quality
  const quality = config.quality !== undefined ? config.quality : 0.8;
  if (quality < 0 || quality > 1) {
    throw new Error('CaptureConfig.quality must be between 0 and 1, got ' + quality);
  }

  // éªŒè¯ maxWidth/maxHeight
  const maxWidth = config.maxWidth || 1920;
  const maxHeight = config.maxHeight || 1080;
  if (maxWidth < 1 || maxWidth > 7680) {
    throw new Error('CaptureConfig.maxWidth must be between 1 and 7680, got ' + maxWidth);
  }
  if (maxHeight < 1 || maxHeight > 4320) {
    throw new Error('CaptureConfig.maxHeight must be between 1 and 4320, got ' + maxHeight);
  }

  // éªŒè¯ interval
  const interval = config.interval || 1000;
  if (interval < 100) {
    throw new Error('CaptureConfig.interval must be at least 100ms, got ' + interval);
  }

  return {
    source: config.source,
    target: config.target,
    format: config.format || 'jpeg',
    quality,
    maxWidth,
    maxHeight,
    interval,
    autoCapture: config.autoCapture || false,
  };
}
```

**æµ‹è¯•**:
```typescript
// VisionAnalyzer.test.ts
describe('input validation', () => {
  it('should throw error for empty apiKey', () => {
    expect(() => {
      new VisionAnalyzer({ provider: 'openai-gpt4v', apiKey: '' });
    }).toThrow('apiKey is required');
  });

  it('should throw error for invalid temperature', () => {
    expect(() => {
      new VisionAnalyzer({
        provider: 'openai-gpt4v',
        apiKey: 'test',
        temperature: 2.0
      });
    }).toThrow('temperature must be between 0 and 1');
  });
});

// ScreenCapture.test.ts
describe('input validation', () => {
  it('should throw error for invalid quality', () => {
    expect(() => {
      new ScreenCapture({
        source: 'canvas',
        target: mockCanvas,
        quality: 1.5
      });
    }).toThrow('quality must be between 0 and 1');
  });
});
```

---

### ä¿®å¤ #3: æå‡æµ‹è¯•è¦†ç›–ç‡

**ç›®æ ‡**: åˆ†æ”¯è¦†ç›–ç‡ä» 75.89% æå‡åˆ° 80%+

**éœ€è¦æ·»åŠ çš„æµ‹è¯•**:

**tests/ScreenCapture.test.ts**:
```typescript
describe('auto-capture error handling', () => {
  it('should call onError when capture fails during auto-capture', async () => {
    jest.useFakeTimers();
    const onError = jest.fn();

    global.document.querySelector = jest.fn()
      .mockReturnValueOnce(new MockHTMLCanvasElement()) // First call succeeds
      .mockReturnValueOnce(null); // Second call fails

    const capture = new ScreenCapture({
      source: 'canvas',
      target: '#canvas'
    }, { onError });

    capture.startAutoCapture(jest.fn());

    // First capture succeeds
    await jest.advanceTimersByTimeAsync(0);
    expect(onError).not.toHaveBeenCalled();

    // Second capture fails
    await jest.advanceTimersByTimeAsync(1000);
    expect(onError).toHaveBeenCalledWith(expect.any(Error));

    capture.stopAutoCapture();
    jest.useRealTimers();
  });
});

describe('unsupported capture sources', () => {
  it('should throw error for custom source without implementation', async () => {
    const config: any = {
      source: 'custom'
    };

    const capture = new ScreenCapture(config);
    await expect(capture.capture()).rejects.toThrow('Unsupported capture source: custom');
  });
});
```

**tests/VisionAnalyzer.test.ts**:
```typescript
describe('network error handling', () => {
  it('should handle network timeout', async () => {
    const analyzer = new VisionAnalyzer({
      provider: 'openai-gpt4v',
      apiKey: 'test-key'
    });

    mockedAxios.post.mockRejectedValueOnce(new Error('Network timeout'));

    await expect(analyzer.analyze({
      screenshot: mockScreenshot,
      prompt: 'test'
    })).rejects.toThrow('Network timeout');
  });

  it('should handle API rate limit', async () => {
    const analyzer = new VisionAnalyzer({
      provider: 'openai-gpt4v',
      apiKey: 'test-key'
    });

    mockedAxios.post.mockRejectedValueOnce({
      response: { status: 429, data: { error: 'Rate limit exceeded' } }
    });

    await expect(analyzer.analyze({
      screenshot: mockScreenshot,
      prompt: 'test'
    })).rejects.toThrow();
  });
});
```

---

### ä¿®å¤ #4: åŒæ­¥æ–‡æ¡£ä¸ä»£ç 

**æ–‡ä»¶**: `README.md`

**æ›´æ–°ç‰¹æ€§åˆ—è¡¨**:
```markdown
## Features

- **Screen Capture**: Capture from Canvas, Video, Display, Window (Screen Capture API)
- **Vision AI Integration**: GPT-4V (OpenAI) and Claude Vision (Anthropic)
- **Game State Recognition**: Automatic detection of 12 game states
- **Flexible Analysis**: Custom prompts and structured responses
- **Performance Optimized**: Configurable quality, resolution, intervals
- **TypeScript**: Full type safety
- **Game Engine Plugins**: Unity (C#) and Unreal Engine (C++)

## Supported Capture Sources

| Source | Description | Platform |
|--------|-------------|----------|
| `canvas` | HTML Canvas element | Browser |
| `video` | HTML Video element | Browser |
| `display` | Screen Capture API | Browser (requires HTTPS) |
| `window` | Alias for `display` | Browser |

**Note**: Custom capture sources are not yet implemented. Use the built-in sources or contact us for custom requirements.
```

**æ·»åŠ é™åˆ¶è¯´æ˜**:
```markdown
## Limitations

### API Limits
- **OpenAI GPT-4V**:
  - Rate limit: 50 requests/min (varies by tier)
  - Max image size: 20MB
  - Cost: ~$0.01-0.03 per image

- **Anthropic Claude Vision**:
  - Rate limit: 40 requests/min
  - Max image size: 10MB
  - Cost: ~$0.015-0.04 per image

### Browser Compatibility
- Chrome/Edge: 91+ (full support)
- Firefox: 88+ (no display capture in incognito)
- Safari: 15+ (requires user permission)

### Image Size
- Recommended: 1920x1080 or smaller
- Maximum: 3840x2160 (will be resized automatically)
- Larger images = higher cost and slower analysis
```

---

### ä¿®å¤ #5: æ·»åŠ  API å¯†é’¥å®‰å…¨è­¦å‘Š

**æ–‡ä»¶**: `README.md`, `src/analysis/VisionAnalyzer.ts`

**README.md æ·»åŠ å®‰å…¨è­¦å‘Š**:
```markdown
## Security

### âš ï¸ API Key Security Warning

**NEVER expose your API keys in client-side code!**

```typescript
// âŒ UNSAFE - DO NOT DO THIS
const analyzer = new VisionAnalyzer({
  provider: 'openai-gpt4v',
  apiKey: 'sk-...' // Exposed in browser console!
});

// âœ… SAFE - Use environment variables in Node.js
const analyzer = new VisionAnalyzer({
  provider: 'openai-gpt4v',
  apiKey: process.env.OPENAI_API_KEY
});

// âœ… SAFE - Use backend proxy in browser
const analyzer = new VisionAnalyzer({
  provider: 'custom',
  apiKey: 'not-used',
  apiEndpoint: '/api/vision' // Your backend endpoint
});
```

### Backend Proxy Example

**Backend (Node.js/Express)**:
```javascript
import OpenAI from 'openai';
import express from 'express';

const app = express();
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.post('/api/vision', async (req, res) => {
  const { screenshot, prompt } = req.body;

  const response = await openai.chat.completions.create({
    model: 'gpt-4-vision-preview',
    messages: [{
      role: 'user',
      content: [
        { type: 'text', text: prompt },
        { type: 'image_url', image_url: { url: `data:image/jpeg;base64,${screenshot.data}` } }
      ]
    }]
  });

  res.json({ content: response.choices[0].message.content });
});
```

**Frontend**:
```typescript
const analyzer = new VisionAnalyzer({
  provider: 'custom',
  apiKey: 'not-used',
  apiEndpoint: '/api/vision'
});

await analyzer.analyzeWithCustom(request, async (req, config) => {
  const response = await fetch('/api/vision', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      screenshot: req.screenshot,
      prompt: req.prompt
    })
  });

  const data = await response.json();
  return {
    content: data.content,
    confidence: 0.8,
    processingTime: 0
  };
});
```
```

**VisionAnalyzer.ts æ·»åŠ è¿è¡Œæ—¶è­¦å‘Š**:
```typescript
constructor(config: VisionConfig, handlers: VisionEventHandlers = {}) {
  this.config = this.normalizeConfig(config);
  this.handlers = handlers;

  // å®‰å…¨è­¦å‘Š
  if (typeof window !== 'undefined' &&
      (config.apiKey.startsWith('sk-') || config.apiKey.startsWith('sk-ant-'))) {
    console.warn(
      '[AGL Vision Security Warning] API key detected in browser environment.\n' +
      'API keys should NEVER be exposed in client-side code.\n' +
      'Consider using a backend proxy. See documentation: https://docs.agl.com/vision/security'
    );
  }
}
```

---

## ğŸŸ¡ Phase 2: ç”Ÿäº§å‡†å¤‡ï¼ˆå»ºè®®ä¿®å¤ï¼‰

### ä¿®å¤ #6: ç§»é™¤æœªå®ç°çš„ç±»å‹å¯¼å‡º

**æ–‡ä»¶**: `src/index.ts`, `src/types/index.ts`

**å½“å‰å¯¼å‡º**:
```typescript
export type {
  // ...
  BatchAnalysisRequest,      // âŒ æœªå®ç°
  BatchAnalysisResponse,     // âŒ æœªå®ç°
  CacheConfig,               // âŒ æœªå®ç°
  PerformanceMetrics,        // âŒ æœªå®ç°
} from './types';
```

**ä¿®å¤æ–¹æ¡ˆ A - ç§»é™¤å¯¼å‡º**:
```typescript
// src/index.ts
export type {
  // Capture types
  CaptureSource,
  ImageFormat,
  CaptureConfig,
  Screenshot,
  CaptureEventHandlers,

  // Vision types
  VisionProvider,
  VisionConfig,
  VisionRequest,
  VisionResponse,
  VisionEventHandlers,

  // Game state types
  GameStateCategory,
  GameState,
  UIElement,
  GameEntity,
  BoundingBox,

  // Analysis types
  PromptTemplate,

  // ç§»é™¤è¿™äº›:
  // BatchAnalysisRequest,
  // BatchAnalysisResponse,
  // CacheConfig,
  // PerformanceMetrics,
} from './types';
```

**ä¿®å¤æ–¹æ¡ˆ B - æ·»åŠ  @experimental æ ‡è®°**:
```typescript
// src/types/index.ts
/**
 * Batch analysis request
 * @experimental Not yet implemented. Planned for v0.2.0
 */
export interface BatchAnalysisRequest {
  // ...
}
```

**æ¨è**: æ–¹æ¡ˆ Aï¼ˆç§»é™¤å¯¼å‡ºï¼‰

---

### ä¿®å¤ #7: æ·»åŠ ç½‘ç»œè¶…æ—¶é…ç½®

**æ–‡ä»¶**: `src/analysis/VisionAnalyzer.ts`

**æ·»åŠ è¶…æ—¶é…ç½®**:
```typescript
export interface VisionConfig {
  provider: VisionProvider;
  apiKey: string;
  model?: string;
  maxTokens?: number;
  temperature?: number;
  apiEndpoint?: string;
  /** Network timeout in milliseconds (default: 30000) */
  timeout?: number;
}
```

**åœ¨ API è°ƒç”¨ä¸­ä½¿ç”¨**:
```typescript
private async analyzeWithOpenAI(request: VisionRequest): Promise<VisionResponse> {
  const { screenshot, prompt, context } = request;

  // ...messages setup...

  const response = await axios.post(
    this.config.apiEndpoint!,
    { model: this.config.model, messages, max_tokens: this.config.maxTokens },
    {
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${this.config.apiKey}`,
      },
      timeout: this.config.timeout || 30000, // 30 ç§’é»˜è®¤è¶…æ—¶
      validateStatus: (status) => status < 500, // å¤„ç† 4xx é”™è¯¯
    }
  );

  // å¤„ç†ç‰¹å®šé”™è¯¯
  if (response.status === 429) {
    throw new Error(
      'API rate limit exceeded. Please try again later or reduce request frequency.'
    );
  }
  if (response.status === 401 || response.status === 403) {
    throw new Error('Invalid API key. Please check your credentials.');
  }
  if (response.status >= 400) {
    throw new Error(`API error: ${response.status} - ${response.statusText}`);
  }

  // ...rest of implementation...
}
```

---

### ä¿®å¤ #8: å®ç°é€Ÿç‡é™åˆ¶ä¿æŠ¤

**æ–°æ–‡ä»¶**: `src/utils/RateLimiter.ts`

```typescript
export interface RateLimitConfig {
  /** Maximum requests per minute */
  maxRequestsPerMinute?: number;
  /** Maximum concurrent requests */
  maxConcurrent?: number;
}

export class RateLimiter {
  private requestTimes: number[] = [];
  private activeRequests = 0;
  private maxRequestsPerMinute: number;
  private maxConcurrent: number;

  constructor(config: RateLimitConfig = {}) {
    this.maxRequestsPerMinute = config.maxRequestsPerMinute || 60;
    this.maxConcurrent = config.maxConcurrent || 5;
  }

  async acquire(): Promise<void> {
    // ç­‰å¾…å¹¶å‘é™åˆ¶
    while (this.activeRequests >= this.maxConcurrent) {
      await this.sleep(100);
    }

    // ç­‰å¾…é€Ÿç‡é™åˆ¶
    while (this.isRateLimited()) {
      const oldestRequest = this.requestTimes[0];
      const waitTime = 60000 - (Date.now() - oldestRequest);
      await this.sleep(Math.max(waitTime, 100));
    }

    this.requestTimes.push(Date.now());
    this.activeRequests++;
  }

  release(): void {
    this.activeRequests--;
  }

  private isRateLimited(): boolean {
    const now = Date.now();
    this.requestTimes = this.requestTimes.filter(time => now - time < 60000);
    return this.requestTimes.length >= this.maxRequestsPerMinute;
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

**é›†æˆåˆ° VisionAnalyzer**:
```typescript
export class VisionAnalyzer {
  private rateLimiter?: RateLimiter;

  constructor(
    config: VisionConfig & { rateLimit?: RateLimitConfig },
    handlers: VisionEventHandlers = {}
  ) {
    this.config = this.normalizeConfig(config);
    this.handlers = handlers;

    if (config.rateLimit) {
      this.rateLimiter = new RateLimiter(config.rateLimit);
    }
  }

  async analyze(request: VisionRequest): Promise<VisionResponse> {
    if (this.rateLimiter) {
      await this.rateLimiter.acquire();
    }

    const startTime = Date.now();
    try {
      const response = await this.analyzeWithProvider(request);
      // ...
      return result;
    } catch (error) {
      throw error;
    } finally {
      if (this.rateLimiter) {
        this.rateLimiter.release();
      }
    }
  }
}
```

---

### ä¿®å¤ #9: æ·»åŠ å›¾ç‰‡å¤§å°é™åˆ¶

**æ–‡ä»¶**: `src/capture/ScreenCapture.ts`

```typescript
export interface CaptureConfig {
  source: CaptureSource;
  target?: HTMLCanvasElement | HTMLVideoElement | string;
  format?: ImageFormat;
  quality?: number;
  maxWidth?: number;
  maxHeight?: number;
  interval?: number;
  autoCapture?: boolean;
  /** Maximum screenshot size in bytes (default: 10MB) */
  maxSize?: number;
}
```

**å®ç°å¤§å°æ£€æŸ¥**:
```typescript
private canvasToScreenshot(canvas: HTMLCanvasElement): Screenshot {
  const resized = this.resizeCanvas(canvas);
  const mimeType = this.getMimeType(this.config.format);
  const dataUrl = resized.toDataURL(mimeType, this.config.quality);
  const base64Data = dataUrl.split(',')[1];
  const size = Math.ceil((base64Data.length * 3) / 4);

  // æ£€æŸ¥å¤§å°é™åˆ¶
  const maxSize = this.config.maxSize || 10 * 1024 * 1024; // 10MB é»˜è®¤
  if (size > maxSize) {
    const sizeMB = (size / 1024 / 1024).toFixed(2);
    const maxSizeMB = (maxSize / 1024 / 1024).toFixed(2);
    throw new Error(
      `Screenshot size (${sizeMB}MB) exceeds maximum allowed size (${maxSizeMB}MB). ` +
      `Try reducing maxWidth, maxHeight, or quality settings.`
    );
  }

  return {
    data: base64Data,
    format: this.config.format,
    width: resized.width,
    height: resized.height,
    timestamp: Date.now(),
    size,
  };
}
```

---

### ä¿®å¤ #10: å®Œå–„æ–‡æ¡£ç¤ºä¾‹

**æ–‡ä»¶**: `README.md`

**æ·»åŠ é”™è¯¯å¤„ç†éƒ¨åˆ†**:
```markdown
## Error Handling

### Handling Capture Errors

```typescript
import { ScreenCapture } from '@agl/vision';

const capture = new ScreenCapture(
  {
    source: 'canvas',
    target: '#game-canvas',
  },
  {
    onError: (error) => {
      console.error('Capture failed:', error.message);

      if (error.message.includes('not a canvas')) {
        console.log('Canvas element not found. Check your selector.');
      } else if (error.message.includes('exceeds maximum')) {
        console.log('Image too large. Reduce quality or resolution.');
      }
    },
  }
);

try {
  const screenshot = await capture.capture();
  console.log('Captured successfully');
} catch (error) {
  console.error('Failed to capture:', error);
}
```

### Handling Analysis Errors

```typescript
import { VisionAnalyzer } from '@agl/vision';

const analyzer = new VisionAnalyzer(
  {
    provider: 'openai-gpt4v',
    apiKey: process.env.OPENAI_API_KEY,
    timeout: 30000,
  },
  {
    onAnalysisError: (error) => {
      console.error('Analysis failed:', error.message);
    },
  }
);

try {
  const response = await analyzer.analyze({
    screenshot,
    prompt: 'What is happening?',
  });
  console.log('Analysis:', response.content);
} catch (error) {
  if (error.message.includes('rate limit')) {
    console.log('Rate limited. Wait and retry.');
    await sleep(60000);
    // Retry logic
  } else if (error.message.includes('Invalid API key')) {
    console.log('Check your API key configuration.');
  } else if (error.message.includes('timeout')) {
    console.log('Request timed out. Try again or increase timeout.');
  } else {
    console.error('Unexpected error:', error);
  }
}
```

### Retry Logic

```typescript
async function analyzeWithRetry(
  analyzer: VisionAnalyzer,
  request: VisionRequest,
  maxRetries = 3
): Promise<VisionResponse> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await analyzer.analyze(request);
    } catch (error) {
      if (i === maxRetries - 1) throw error;

      const delay = Math.pow(2, i) * 1000; // Exponential backoff
      console.log(`Retry ${i + 1}/${maxRetries} after ${delay}ms`);
      await sleep(delay);
    }
  }
  throw new Error('Max retries exceeded');
}

function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}
```
```

**æ·»åŠ ç¯å¢ƒé…ç½®éƒ¨åˆ†**:
```markdown
## Environment Setup

### Development

Create a `.env` file in your project root:

```env
# OpenAI
OPENAI_API_KEY=sk-...

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...
```

Load environment variables:

```typescript
import dotenv from 'dotenv';
dotenv.config();

const analyzer = new VisionAnalyzer({
  provider: 'openai-gpt4v',
  apiKey: process.env.OPENAI_API_KEY!,
});
```

### Production

**Option 1: Environment Variables**
```bash
# Set in your deployment platform
export OPENAI_API_KEY="sk-..."
```

**Option 2: Backend Proxy (Recommended)**
- Never expose API keys in client-side code
- Use a backend service to proxy requests
- Implement your own rate limiting and logging
- See [Backend Proxy Example](#backend-proxy-example) above
```

---

## ğŸ“‹ ä¿®å¤æ£€æŸ¥æ¸…å•

### Phase 1ï¼ˆç´§æ€¥ï¼‰

- [ ] ä¿®å¤ #1: ç±»å‹å®šä¹‰ä¸åŒ¹é…
  - [ ] æ›´æ–° `CaptureSource` ç±»å‹
  - [ ] æ›´æ–°æ–‡æ¡£
  - [ ] æ·»åŠ æµ‹è¯•

- [ ] ä¿®å¤ #2: è¾“å…¥éªŒè¯
  - [ ] VisionAnalyzer éªŒè¯
  - [ ] ScreenCapture éªŒè¯
  - [ ] æ·»åŠ æµ‹è¯•

- [ ] ä¿®å¤ #3: æµ‹è¯•è¦†ç›–ç‡
  - [ ] Auto-capture é”™è¯¯æµ‹è¯•
  - [ ] ä¸æ”¯æŒæºæµ‹è¯•
  - [ ] ç½‘ç»œé”™è¯¯æµ‹è¯•
  - [ ] ç¡®è®¤è¦†ç›–ç‡ â‰¥ 80%

- [ ] ä¿®å¤ #4: æ–‡æ¡£åŒæ­¥
  - [ ] æ›´æ–°ç‰¹æ€§åˆ—è¡¨
  - [ ] æ·»åŠ é™åˆ¶è¯´æ˜
  - [ ] æ›´æ–°ç¤ºä¾‹

- [ ] ä¿®å¤ #5: å®‰å…¨è­¦å‘Š
  - [ ] README è­¦å‘Š
  - [ ] ä»£ç è¿è¡Œæ—¶è­¦å‘Š
  - [ ] åç«¯ä»£ç†ç¤ºä¾‹

### Phase 2ï¼ˆå»ºè®®ï¼‰

- [ ] ä¿®å¤ #6: ç§»é™¤æœªå®ç°ç±»å‹
- [ ] ä¿®å¤ #7: ç½‘ç»œè¶…æ—¶
- [ ] ä¿®å¤ #8: é€Ÿç‡é™åˆ¶
- [ ] ä¿®å¤ #9: å›¾ç‰‡å¤§å°é™åˆ¶
- [ ] ä¿®å¤ #10: æ–‡æ¡£ç¤ºä¾‹

---

## ğŸ“Š é¢„æœŸç»“æœ

### ä¿®å¤åæŒ‡æ ‡

| æŒ‡æ ‡ | ä¿®å¤å‰ | ç›®æ ‡ |
|------|--------|------|
| æµ‹è¯•è¦†ç›–ç‡ï¼ˆåˆ†æ”¯ï¼‰ | 75.89% | â‰¥ 80% |
| ç±»å‹å®‰å…¨æ€§ | éƒ¨åˆ† | å®Œå…¨ |
| æ–‡æ¡£å‡†ç¡®æ€§ | 85% | 95% |
| ç”Ÿäº§å°±ç»ªåº¦ | B çº§ | A çº§ |

### å‘å¸ƒè®¡åˆ’

1. **v0.1.1-beta**: Phase 1 ä¿®å¤
2. **v0.1.1**: Phase 1 + ç”¨æˆ·åé¦ˆä¿®å¤
3. **v0.2.0**: Phase 2 ä¿®å¤

---

**é¢„è®¡æ€»å·¥ä½œé‡**: çº¦ 20 å°æ—¶ï¼ˆ2-3 å¤©å…¨èŒå·¥ä½œï¼‰
